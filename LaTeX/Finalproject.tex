\documentclass {article}
\usepackage{amsmath}
\usepackage{theoremref}

\title{Calculating a correct compiler using the Bahr and Hutton method}
\author{Marco Jones}

\begin{document}
\begin{titlepage}
\maketitle
\end{titlepage}

\tableofcontents
\clearpage

\newcommand{\BH}{Bahr and Hutton}
\newcommand{\vm}{virtual machine}

\section{Introduction}

Ever since the invention of electronic computers
the instruction set to operate them has grown massively.
At the lowest level, computers directly execute
a series of discrete binary electrical
pulses using logical circuits 
to perform operations which can be used to perform computation.

These binary signals are far from random; they're formally
defined in a grammar, making it a \emph{language},
more specifically the language of ``Machine code'' instructions.
Managing operations in machine code is inefficient on
a large scale,
so programmers have developed 
higher level programming languages
by abstracting away from the details of how a computer works,
these languages are easier for programmers to interpret
than machine code.

A programming language is defined by
a compiler and virtual machine. %ask colin
A compiler translates the high level
\emph{source language} into a 
lower level \emph{target language}.
The end result of compilation is the program
translated into assembly language,
from here an assembler translates the assembly code
into machine code for the computer to execute.

Compilers are written in a programming
language just like any other program 
and developed by a similar process;
a programmer has an idea of what features a program
is to have, implements, 
and performs tests to verify it's correctness.

\BH\ have developed a simple technique, for
calculating a compiler and virtual machine via equational reasoning
for a given source language and its' semantics \cite{bandh}, 
whilst simultaneously guaranteeing it's correctness by virtue 
of \emph{constructive induction} \cite{backhouse}.

Through the inductive process we discover 
and invent definitions
of our compiler and virtual machine 
without needing to wholly specify how the 
machine should operate before hand.
The result, is an equational program consisting of
definitions of the compile function and \vm,
and any axillary functions we create in the process.

\subsection{Aims and methodology}

The aim of this dissertation is to
see whether the \BH\ method can
be used to calculate a new and correct compiler
with a corresponding \vm, 
not defined in their paper \cite{bandh}.
The compiler and \vm\ we will calculate 
will be for a source language which extends 
upon the Arithmetic language example\cite[Section 2]{bandh},
and will do so in three stages.

Firstly by summarising the \BH\ method,
using the arithmetic language derivation 
as described in, as a guide.

Secondly, the language will be gradually extended
by calculating new definitions of a more complex nature,
and implementing them in Haskell
\footnote{Haskell provides curried function application
		and explicit type declaration which are
		convenient for defining grammars,
		as consequence, the implementation closely
		resembles our calculations}.
Each extension of the language will be labelled 
as it's own language, it's compiler and \vm\ 
will be provided in it's own .hs file supporting
this document.
We will see the \BH\ method used to calculate
the language of: conditionals, variable bindings
and function definitions.

Each calculation we will be briefly tested
using an example expression
in three different ways.

\begin{enumerate}
	\item Compare hand compiled code against the
		implemented compiler.
	\item Compare results of hand executed code 
		against that of the \vm.
	\item Compare outputs of the \vm\ against the interpreter.
\end{enumerate}

Thirdly, we will use automated testing
to verify the definitions in the final
and most extended language; 
by construction, the automated
tests should verify all calculations up
to and including the 
should all tests pass, we will
be even more confident in our 
compiler's correctness

Finally, we will conclude with 
reflection on using the \BH\ method,
and further work.

\subsection{Roadmap}

Section \ref{bhrev} will review the \BH\ method 
and a short literature review on compiler
proof. The \BH method is
a process of constructing a correct 
compiler from the beginning; its construction
serves as it's proof,
however compiler proof is a related topic.

In sections \ref{langcond} and \ref{langbind}
 we will derive compiler and
virtual machine definitions for: a conditional function, 
and variable declaration function.

In section \ref{autotesting} we will discuss the method
of systematically testing the compiler and virtual machine.

\section{A review of the Bahr and Hutton method} \label{bhrev}

Sections 2.1 - 2.4 of \BH's paper describe the unrefined 
method in detail, only to refine the process
in section 2.5 \cite[2.5 Combining the transformation steps]{bandh},
resulting in a much simpler 3 step process, 
this paper will only be concerned with
their refined 3 step method\cite[page 12]{bandh}.
Here are the 3 steps:

\begin{enumerate}
	\item Define an evaluation function
		in a compositional manner.
	\item Define equations that specify
		the correctness of the compiler.
	\item Calculate definitions that 
		satisfy these specifications.
\end{enumerate}

In section 2 they are deriving a compiler
and virtual machine for the ``Arithmetic'' language,
they begin by defining: a new Haskell data type $Expr$;
which contain the set of expressions which belong to their source language,
an evaluation function, also referred to as the \emph{interpreter},
which defines their semantics,
and a stack of integers where 
arguments are manipulated.
\newcommand{\eval}{\textit{eval}}
\newcommand{\expr}{\textit{Expr}}
\newcommand{\val}{\textit{Val}}
\newcommand{\add}{\textit{Add}}
\newcommand{\code}{\textit{Code}}
\newcommand{\Val}{\mathit{Val\ }}
\newcommand{\Add}{\mathit{Add\ }}
\newcommand{\evalf}{\mathit{eval\ }}
\newcommand{\Expr}{\mathit{Expr\ }}
\newcommand{\Int}{\mathit{Int\ }}
\begin{eqnarray}
\textbf{type} \ Stack &=& [\mathit{Int}] \nonumber \\
\textbf{data} \Expr &=& \Val \Int | \ \Add \Expr \Expr \nonumber \\
\evalf &::& \Expr \rightarrow \mathit{Int} \nonumber \\ 
\evalf (\Val  n) &=& n \label{evalval}\\
\evalf (\Add  x\  y) &=& \evalf  x + \evalf  y \label{evaladd}
\end{eqnarray}

In Haskell \textbf{data} creates a new type,
here we define \expr\ as either being a \val\
or an \add, these tags are called \emph{constructors},
a $Val$ constructor will always be followed by an integer
(which is ``Int'' in Haskell),
and an Add will always be followed by two more expressions.
It is the constructor \emph{together} with 
it's arguments that make it of \textbf{type}
expression, i.e \val\ $n$ or \add\ $x\ y$,
where $n$ is an $Int$ and $x$ and $y$ are $Expr$,
if the constructors are not followed by .
However because of curried function application,
we cannot simply write 
$eval\ Val\ n$ or $eval\ Add\ x\ y$,
because that applies \eval to 2 and 3 arguments respectively,
thus we package each expression into a single arguments
by using parentheses, so long as each ``package'' is a
valid \expr, the function application will be type correct
and we may continue e.g.
\[ \evalf (\Add (\Val 1)\ (\Val 2)) \]

On the right hand side of the equations is a
description of how to compute 
the result of what \eval\ is applied to.
Evaluating a \val\ expression simply returns $n$
on the other hand evaluating an \add\
is recursively defined, as we do not yet know
the values of \eval\ $x$ and  \eval\ $y$; \BH\ are defining the
semantics of $Add\ x\ y$ \emph{compositionally} by the 
semantics of each of it's argument expressions, $x$ and $y$.

Making the semantics compositional allows
the use of \textit{inductive} derivations,
this means that for a given 
function applied to an expression
we assume it's \textit{type correct} and seek to find
a definition for it, which will hold true in
all cases regardless of what it's arguments are.
\BH\ explore
when this is not possible, but that is beyond
the aim of this project \cite{bandh}.

In sections 2.1 - 2.4 \BH\
\emph{derived} four 
components and two correctness equations\cite{bandh}~[page~9]:
\newcommand{\exec}{\textit{exec}}
\newcommand{\comp }{\textit{comp}}
\newcommand{\compp}{\textit{comp'}}
\newcommand{\Exec}{\mathit{exec\ }}
\newcommand{\Comp}{\mathit{comp\ }}
\newcommand{\Compp}{\mathit{comp'\  }}
\begin{itemize}
\item A data type \code\ that represents
	code for the virtual machine.
\item A function \( \Comp :: \Expr \rightarrow \code \)
	that compiles source expressions to code.
\item A function 
	\( \Compp::Expr \, \rightarrow \, \code \, \rightarrow \, \code \)
	that also takes a code continuation as input.
\item A function
	\( \Exec :: \code \, \rightarrow \, \textit{Stack} \, \rightarrow \, \textit{Stack} \)
	that provides a semantics for code by modifying a run-time stack.
\end{itemize}
\begin{eqnarray}
\Exec  (\Comp   x)\  s &=& \evalf x:s \label{spec1}\\
\Exec  (\Compp  x\  c)\ s &=& \Exec  c\  (\evalf x:s) \label{spec2}
\end{eqnarray}

Calculations begin in the form the 
specification of compiler correctness i.e equation (\ref{spec2}),
and proceed by constructive induction on expression $x$, 
and aim to re-write it into the form
\exec\  $c'\  s$ for some code $c'$
from which we can then conclude that the new definition
for the compile function: \( \Comp  x\  c = c' \) 
which satisfies the specification\cite{bandh}.

It is perhaps simple in appearance,
but this equation
specifies the correctness of compilation of our entire source code,
moreover all of the source code is contained within  $c$
and we compile all of it by recursively calling the \compp\ function.
Bundling the source code into a 
single variable may seem optimistic, but a lot of compilers nowadays 
take entire programs as a (possibly huge) string of characters
and it is often up to a preprocessor to collect 
them together into tokens, and analyse syntax, 
this process is done a single letter or symbol at a time\cite{dragon}.
We won't be using special syntax in our language and so won't
require a parser, instead our functions are  Haskell constructors, 
which state the type of arguments and gives us an \emph{abstract} syntax.

\subsection{Example calculations}

To introduce the \BH\ method,
we will follow the 
calculation of \comp and \exec\ definitions
for \val\ and \add\ expressions\cite[section 2.5]{bandh}.

Starting from the compiler specification (\ref{spec1})
where the expression $x$
is the base case $Val\ n$, 
the calculation proceeds as follows\cite{bandh}:
\begin{align*}
&\Exec (\Compp (Val\ n)\ c)\ s \\
=\, & \{ \mbox{definition of \eval} \} \\
&\Exec c\ (\evalf (Val\ n) : s) \\
=\, & \{ \mbox{definition of \eval} \} \\
&\Exec c\ (n:s)
\end{align*}

Now there are no further definitions that we can apply,
but we must invent a definition for $exec$ which allows
us to proceed; by solving the equation:

\[ \Exec  c'\ s = \Exec  c\ (n : s) \]

Currently our calculation is the form of
the right hand side of this equation,
however $c$ and $n$ are now \emph{unbound}
along with the new variable $c'$;
they only appear on one side of the equation,
so we cannot use this equation as a definition
for \exec\ or \comp.
This is similar to declaring unknown variables 
in algebra, one cannot use an unknown variable to define
another without also making it's value unknown,
in the same way we can't use expressions with
unbound variables to define other expressions,
e.g \(b = a + c\ | \textit{where}\ c = 1\), we cannot
know the value of $y$ if $x$ is not given.

Therefore to solve this equation we are to
define what $c'$ is in terms of 
the other unbound variables $c$ and $n$,
$c'$ is of  type \code\ 
so with a new instruction that takes $n$
and $c$ as arguments we can bind them both\cite[bottom of page 9]{bandh},
\newcommand{\PUSH}{\textit{PUSH\ }}
\begin{eqnarray}
\PUSH &::& Int \rightarrow Code \rightarrow Code \nonumber \\
\Exec (\PUSH n\ c)\ s &=& \Exec c\ (n :s)
\end{eqnarray}

This defines a definition for \exec, 
that executing the code \( (\PUSH n\ c) \) 
pushes the value n onto the stack $s$
then executes the code $c$ by making use of 
a recursive definition.
\begin{align*}
&\Exec c\ (n:s) \\
=\, & \{\mbox{definition of \exec}\} \\
&\Exec  (\PUSH n\ c)\ s
\end{align*}

Our equation is now in the form $\Exec c'\ s$
where $c' = \PUSH n\ c$. We began from 
\(\Exec (\Compp (\Val n)\ c)\ s \),
and every equation was valid in the derivation,
therefore it is safe to conclude that 
\begin{equation}
\Exec (\Compp (\Val  n)\ c)\ s = \Exec  (\PUSH n\ c)\ s \label{compval}
\end{equation}

\noindent or more specifically, we have \emph{discovered} 
a definition for the compiler
\[ \Compp  (Val\ n)\ c =  \PUSH n\ c \]

Next \BH\ calculate definitions for the inductive case, 
$\Add x\ y$,
we call it inductive because we don't yet know 
the values of $x$ and $y$ however we are assuming
that they are expressions as well,
otherwise there would be a type error.
Starting from a similar point,

\begin{align*}
&\Exec (\Compp  (Add\ x\ y)\ c)\ s \\
=\, & \{ \mbox{specification of the compiler (\ref{spec2})} \} \\
&\Exec c\ (\evalf (\Add x\ y) : s) \\
=\, & \{ \mbox{definition of \eval} \} \\
&\Exec c\ (\evalf x + \evalf y :s)
\end{align*}

Again we are stuck, however similar to before, 
we can make a new definition for $exec$ which 
will allow us to continue.
Moreover being an inductive case, 
we can make use of the induction 
hypotheses for $x$ and $y$,
these hypotheses are equations in the form
of the equation for compiler correctness \ref{spec2},
with specific values for $x$ and $s$,
they tell us what to compile in order to achieve
a certain stack state.
\begin{eqnarray}
\Exec (\Compp  x\ c)\ s &=& \Exec c\ (eval\ x:s) \label{iniduc1}\\
\Exec (\Compp  y\ c)\ s &=& \Exec c\ (eval\ y:s) \label{iniduc2}
\end{eqnarray}

In this case the hypotheses are similar;
the hypothesis for $x$ assumes that $\evalf x$
is on top of the stack,
whereas the hypothesis for $y$ assumes $\evalf y$
is on top.
To be able to use either, we must manipulate 
our stack into one of the forms on the RHS
on the induction hypotheses.
The aim is to have both evaluations of $x$ and $y$
to make the addition,
therefore we need to use both hypotheses
one after the other.
With this in mind, 
we need to have stack with both \eval\ $x$ and $y$ on top, i.e. 
 \( \evalf x : \evalf y : s \)
(or vice versa).
Just like with \val,
we can invent a new instruction
to get the stack into that state.
In doing so, we will solve the equation:
\begin{equation*}
\Exec  c'\ (\evalf x : \evalf y : s) 
	= \Exec  c\ (\evalf x + \evalf y :s)
\end{equation*}

\newcommand{\ADD}{ADD\ }

So we define ADD that
when executed, adds the top two stack elements
together and leaves the result on top of the stack.
\begin{eqnarray}
ADD &::& Code \rightarrow Code \nonumber \\
\Exec (\ADD c)\ (m:n:s) &=& \Exec c\ (n+m:s)
\end{eqnarray}

Ordering is not important in this case; it is a matter of choice.
\BH\ mention here that their choice is to use
left-to-right evaluation by pushing $\evalf x$ on first,
for consistency, we will use their definition.

Now we have the operation definition for the 
virtual machine we continue the calculation 

\begin{align*}
&\Exec c\ (\evalf x + \evalf y :s) \\
=\, & \{ \mbox{defintion of}\ \exec\} \\
&\Exec (\ADD c)\ (eval\ y : eval\ x : s) \\
=\, & \{ \mbox{induction hypothesis for}\  y \} \\
&\Exec (\Compp y\ (\Compp x\ (\ADD c)))\ s
\end{align*}

The final expression is now in the form
\( \Exec c'\ s \), we started from
\( \Exec (\Compp  (\Add x\ y)\ c)\ s \)
which means we can conclude that 
\begin{eqnarray*}
\Exec c'\ s &=& \Exec (\Compp  (\Add x\ y)\ c)\ s \\
\mbox{where}\ c' &=& \Compp y\ (\Compp x\ (\ADD c))
\end{eqnarray*}

In summary, we have discovered a definition for the
compiler
\begin{equation*}
\Compp  (Add\ x\ y)\ c
= \Compp y\ (\Compp x\ (\ADD c))
\end{equation*}

Discovering this definition is the 
whole point of the calculation process.
Just from the definition of the high level semantics 
of a \val\ source expression, and the specification 
of compiler correctness, we've come across the
exact situation where we need a new instruction
to solve a specific problem,
and then made it. After that we applied induction
hypotheses to find definitions for the compiler. 
Proceeding like this, we can
define more source code to expand our arithmetic language.

An important aspect of the \BH method
is that the equations that construct the 
compiler serve as proof of it's correctness,
and so they explain that a derivation such as
this one can be read as a proof \cite[page 14]{bandh}.
This will not show us much at the moment,
but will be used later on.

In summary \BH\ calculated the following definitions\footnote{
The instruction HALT simply returns the current state of the stack,
I didn't include \BH's derivation of HALT for brevity because
it's only a small point}
for the compiler and virtual machine:

\begin{eqnarray}
	&\textbf{data}\ Code &= HALT | PUSH Int Code | ADD Code \nonumber \\
	&comp &:: Expr \rightarrow Code \nonumber \\
	&\Comp x &= \Compp  x\ HALT \label{comp}\\
	&comp' &:: Expr \rightarrow Code \rightarrow Code \nonumber \\
	&\Compp  (Val\ n)\ c &= \PUSH n\ c \nonumber \\
	&\Compp  (Add\ x\ y)\ c 
				&= \Compp  x\ (\Compp  y (ADD\ c)) \label{compadd}\\
	&exec &:: Code  \rightarrow Stack \rightarrow Stack \nonumber \\
	&\Exec HALT\ s &= s \label{exechalt}\\
	&\Exec (\PUSH n\ c)\ s &= \Exec c\ (n:s) \label{execpush}\\
	&\Exec (ADD\ c)\ (m:n:s) &= \Exec c\ ((n + m):s) \label{execadd}
\end{eqnarray}

\subsection{Testing Add and Val expressions}

To conclude this section I will test the functionality
of Add and Val, with a somewhat complicated
example.
This will give us a chance to look at the code that their
compiler generates and how the virtual machine executes it.

In checking these calculations, we can do several tests:
Calculate and compare by hand 
the code that is produced or executed
by the compiler definitions, 
against the results using the Haskell implementation in GHCi.
Compare the result of the executed code against the result
given by the interpreter. 
This result is arguably the most
important because if a counter example is found,
then our specification for compiler correctness 
\[ \Exec (\Compp  x\ c) s = \Exec c\ (eval\ x : s) \]
does not always hold, 
which means our calculations were wrong
assuming the test expression is valid.

%After these tests we can prove the equations meet the specification
%by the method that \BH describe in CCC \cite[page 14; derivation vs proof]{bandh}

The equation we'll be looking at is:

\[ Add\ (Add\ (Val\ 0)\ (Val\ 1))\ (Val\ 2)) \]

This expression was chosen because it 
will test that each sub-expression
is compiled properly, 
this is more of a general test of the
\comp\ and \compp\ functions. 
In future we won't need to use
such complicated examples, 
especially when functions become more complicated.

\subsubsection{Compilation}

\begin{align*}
&\Comp (Add\ (Add\ (Val\ 0)\ (Val\ 1))\ (Val\ 2)) \\
&= \{ definition\ \ref{comp} \} \\
&\Compp  (Add\ (Add\ (Val\ 0)\ (Val\ 1))\ (Val\ 2))\ 			(HALT) \\
=\, & \{ definition\ \ref{compadd} \} \\
&\Compp  (Add\ (Val\ 0)\ (Val\ 1))\ (\Compp  (Val\ 2) 	  (ADD\ HALT)) \\
=\, & \{ definitions\ \ref{compadd}\ and\ \ref{compval}\ \} \\
&\Compp  (Val\ 0)\ (\Compp  (Val\ 1)\		(ADD\ (\PUSH 2\ (ADD\ HALT)))) \\
=\, & \{ definition\ \ref{compval}\ twice\ \} \\
&					 \PUSH 0\ (\PUSH 1\ (ADD\ (\PUSH 2\ (ADD\ HALT)))) \\
\end{align*}

This agrees with the same expression being compiled
using the Haskell implementation of the compiler.
GHCi: \( \PUSH 0\ (\PUSH 1\ (ADD\ (\PUSH 2\ (ADD\ HALT)))) \)

\subsubsection{Execution}

The LHS contains the function representing our \vm\
and the RHS is the current state of the run-time stack

\begin{align*}
&\Exec (\PUSH 0\ (\PUSH 1\ (ADD\ (\PUSH 2\ (ADD\ HALT))))) &[\, ] \\
=\, & \{ definition\ \ref{execpush}\ twice \} \\
&\Exec (ADD\ (\PUSH 2\ (ADD\ HALT))) 					&[1,\ 0] \\
=\, & \{ definition\ \ref{execadd} \} \\
&\Exec (\PUSH 2\ (ADD\ HALT)) 								&[1] \\
=\, & \{ definition\ \ref{execpush} \} \\
&\Exec (ADD\ HALT)										 &[2,\ 1] \\
=\, & \{ definition\ \ref{execadd} \} \\
&\Exec HALT 												&[3] \\
=\, & \{ definition\ \ref{exechalt} \} \\
&[3]
\end{align*}

\subsubsection{Interpretation}

\begin{eqnarray*}
	 eval (Val\  n) &=& n \\
	 eval (Add\  x\  y) &=& eval\  x + eval\  y 
\end{eqnarray*}

\begin{align*}
	&eval\ (Add\ (Add\ (Val\ 0)\ (Val\ 1))\ (Val\ 2)) \\
	=\, & \{ \ref{evaladd} \} \\
	&eval\ (Add\ (Val\ 0)\ (Val\ 1))\ +\ eval\ (Val\ 2) \\
	=\, & \{ \ref{evaladd}\ and\ \ref{evalval} \} \\
	&eval\ (Val\ 0)\ +\ eval\ (Val\ 1)\ +\ 2 \\
	=\, & \{ \ref{evalval}\ twice\} \\
	&0\ +\ 1\ +\ 2 \\
	=\, & \{ arithmetic \} \\
	&3
\end{align*}

The results of the execution and interpretation test
agree with each other and with the same tests
using the Haskell implementation of the \vm\ and interpreter.
GHCi: \( [3],\ 3 \)


%\subsubsection{Proof}
%
%\begin{align*}
%	&\Exec (\Compp  (Add\ x\ y)\ c)\ s \\
%	=\, & \{specification\ (4) \} \\
%	&\Exec c\ (eval\ (Add\ x\ y) : s) \\
%	=\, & \{\mbox{defintion of}\ eval\} \\
%	&\Exec c\ (eval\ x + eval\ y :s) \\
%	&ADD :: Code \rightarrow Code \\
%	&\Exec (ADD\ c)\ (m:n:s) = \Exec c\ ((n+m:s)) \\
%	=\, & \{ defintion\ of\ exec \} \\
%	&\Exec (ADD c)\ (eval\ y : eval\ x : s) \\
%	=\, & \{ \mbox{induction hypothesis}\ for\ y \} \\
%	&\Exec (\Compp  y\ (\Compp  x\ (ADD\ c))) s
%\end{align*}

%%%%%%%%%%%%%%%%%%%%	CONDITIONALS	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Conditionals, $L_c$} \label{langcond}

From now on this dissertation will report on my
investigation into applying the \BH\ method to develop a compiler
with definitions not defined in CCC.

To start off with, we will derive a conditional operator,
the purpose of this was to practise the method
on an operation only slightly more complicated than
the addition operation that \BH\ derived.

\newcommand{\ite}{$Ite$}

Step 1 is: 
``define an evaluation function in a compositional manner''.
We are still using the same \eval\ function from before,
but we need to define a new 
expression and it's semantics.

Haskell conditionals concrete
syntax ``if  x then y else z'',
however without a parser to do
lexical analysis\cite[chapter 2.2]{dragon} of the lexemes\footnote{
``if'', ``then'' and ``else'' in this case},
our \emph{source} language cannot use this
syntax, so we define ours abstractly.
In general conditionals are formed out of three parts:
a condition, a true case, and a false case.
In our language these will be three expressions
that follow an ``\ite'' constructor.

	\[ \textbf{data}\ Expr = ... | Ite\ Expr\ Expr\ Expr \]

the semantics of it will be

\begin{equation}
eval(Ite\ x\ y\ z) \\
	= if\ eval\ x \not= 0 then\ eval\ y\ else\ eval\ z 
			\label{evalite}
\end{equation}

The condition $eval\ x  \not= 0$ is very basic,
and we may benefit more from having variable conditions
which we could define at source level,
that could be done if we had an evaluation function 
that could return boolean values, 
however for the purpose of this calculation
this fixed condition will do.

More importantly, the semantics of \ite\
are compositional, 
again because we have defined it's
semantics in terms of the semantics of 
it's arguments so
calculations about \ite\ expressions
will be \emph{inductive}.

step 2: ``Define equations that specify the correctness of the compiler''.
The \\Exec and \\Comp functions still take the same
type of arguments as before,
so there is no need to update the specifications yet

\begin{eqnarray*}
	 &\Exec  (\Comp  x)\  s &= eval\  x:s \\
	 &\Exec  (\Compp   x\  c)\ s &= \Exec  c\  (eval\ x:s) 
\end{eqnarray*}

\subsection{Calculation}

Step 3: ``Calculate definitions that 
		satisfy these specifications''

In order to satisfy specification 2,
we begin with it's LHS where $x$ is our
\ite\ expression.

\begin{align*}
	&\Exec (\Compp  (Ite\ x\ y\ z)\ c)\ s \\
	=\, & \{specification\ (2) \} \\
	&\Exec c\ (eval\ (Ite\ x\ y\ z) : s) \\
	=\, & \{\mbox{defintion of}\ eval\} \\
	&\Exec c\ (if\ eval\ x \not= 0\ then\ eval\ y\ else\ eval\ z :s)
\end{align*}

There are no more definitions to apply from here,
it's clear that we required to
create a new definition for $exec$,
and because this is an inductive calculation
we can use the inductive hypotheses
just like with \BH's calculation of \add.

The inductive hypotheses are:
\begin{eqnarray*}
	\Exec (\Compp  x\ c)\ s &=& \Exec c\ (eval\ x:s) \\
	\Exec (\Compp  y\ c)\ s &=& \Exec c\ (eval\ y:s) \\
	\Exec (\Compp  z\ c)\ s &=& \Exec c\ (eval\ z:s)
\end{eqnarray*}

However, to be able to use them,
we must push $eval\ x,y,z$ onto the stack
in some order of our choice.
So we must solve the generalised equation:

	\[ \Exec c'\ (k:m:n:s) 
		= \Exec c\ (if\ k \not= 0\ then\ m\ else\ n:s)\]

Our code constructor to solve this will be

	\[ ITE :: Code \rightarrow Code \]

and it's definition for the \vm

	\[ \Exec (ITE\ c)\ (k:m:n:s) 
		= \Exec c\ (if\ k \not= 0\ then\ m\ else\ n:s) \]

i.e executing and ITE instruction
checks the top of the stack for the condition $k \not= 0$
and if so, then k and n are removed,
else k and m are removed.
Using this to continue the calculation, we have

\begin{align*}
	&\Exec c\ (if\ eval\ x\ \not= 0\ then\ eval\ y\ else\ eval\ z :s) \\
	=\, & \{\mbox{defintion of}\ exec\} \\
	&\Exec (ITE\ c)\ (eval\ x:eval\ y:eval\ z:s) \\
	=\, & \{\mbox{induction hypothesis}\ for\ x\} \\
	&\Exec (\Compp  x\ (ITE\ c))\ (eval\ y:eval\ z:s) \\
	=\, & \{\mbox{induction hypothesis}\ for\ y\} \\
	&\Exec (\Compp  y\ (\Compp  x\ (ITE\ c)))\ (eval\ z:s) \\
	=\, & \{\mbox{induction hypothesis}\ for\ z\} \\
	&\Exec (\Compp  z\ (\Compp  y\ (\Compp  x\ (ITE\ c))))\ s
\end{align*}

I conclude from this calculation these new definitions
for the compiler and \vm: 

\begin{eqnarray}
	\Compp  (Ite\ x\ y\ z)\ c &=&  \Compp  z\ (\Compp  y\ (\Compp  x\ (ITE\ c))) \label{compite}\\
	\Exec (ITE\ c)\ (k:m:n:s) &=& \Exec c\ ((if\ k \not= 0\ then\ m\ else\ n):s) \label{execite}
\end{eqnarray}

\subsection{Testing}

For the testing, we can create an example \ite\ expression

	\[Ite\ (Val\ 1) (Add\ (Val\ 2) (Val\ 3)) (Add\ (Val\ 4) (Val\ 5)))) \]

This expression would test that
each of the sub-expressions 
(\add\ and \val) compile properly first, 
and that the result of the condition is correct
\footnote{
For completeness we would need to 
test both True and False outcomes of the condition,
such tests are included in the supporting Haskell files, 
however the by hand calculations are omitted
for brevity because they would not add much new
information to these series of tests}.

\subsubsection{Compilation}

\begin{align*}
	&comp' (Ite\
			(Val\ 1)
			(Add\ (Val\ 2)\ (Val\ 3))
			(Add\ (Val\ 4)\ (Val\ 5))) \\
	=\, & \{ equation\ \ref{compite} \}\ \\ 
	&\Compp  (Add\ (Val\ 4)\ (Val\ 5))\\
		&(\Compp  (Add\ (Val\ 2)\ (Val\ 3))\\
			&(\Compp  (Val\ 1)\ (ITE\  HALT))) \\
	=\, & \{ equations\ \ref{compadd}\ twice,\ and\ \ref{compval}\ once\} \\
	&\Compp  (Val\ 4)\ 
		(\Compp  (Val\ 5)\ \\
				&(ADD\ (\Compp  (Val\ 2)\ 
						(\Compp  (Val\ 3)\ \\
							&(ADD\ (\PUSH 1\ 
								(ITE\ HALT))))))) \\
	=\, & \{equation\ 3,\ 4\ times \} \\
	&\PUSH 4\ (\PUSH 5\ 
		(ADD\ (\PUSH 2\ (\PUSH 3\ 
			(ADD\ (\PUSH 1\ (ITE\ HALT)))))))
\end{align*}

This agrees with the same expression being compiled
using the Haskell implementation of the compiler.
GHCi:
\[ \PUSH 4\ (\PUSH 5\
	(ADD\ (\PUSH 2\ (\PUSH 3\ 
		(ADD\ (\PUSH 1\ (ITE\ HALT))))))) \]
	
\subsubsection{Execution}

In executing this code with an empty stack, we get: [5]

By hand, this calculation is as follows:
\begin{align*}
	&exec \, (PUSH \, 4\, (PUSH \, 5\, 
			(ADD\, (PUSH \, 2\, (PUSH \, 3\, 
			(ADD\, (PUSH \, 1\, (ITE\, HALT))))))))\ &[\, ] \\
	=\, & \{equation\ \ref{execpush},\ twice\} \\ 
	&\Exec (ADD\ (\PUSH 2\ (\PUSH 3\ 
			(ADD\ (\PUSH 1\ (ITE\ HALT))))))\ &[5,4] \\
	=\, & \{equation\ \ref{execadd}\} \\
	&\Exec (\PUSH 2\ (\PUSH 3\ 
			(ADD\ (\PUSH 1\ (ITE\ HALT)))))\ &[9] \\
	=\, & \{equation\ \ref{execpush}, twice\} \\ 
	&\Exec (ADD\ (\PUSH 1\ (ITE\ HALT)))\ &[3, 2, 9] \\
	=\, & \{equation\ \ref{execadd}\} \\
	&\Exec (\PUSH 1\ (ITE\ HALT))\ &[5, 9] \\
	=\, & \{equation\ \ref{execpush}\} \\
	&\Exec (ITE\ HALT) &[1, 5, 9] \\
	=\, & \{equation\ \ref{execite}\} \\
	&\Exec HALT\ &[5] \\
	=\, & \{equation\ \ref{exechalt}\} \\
	&[5]
\end{align*}

Interpreting the expression\footnote{
Recall that the interpreter returns an Int rather than a stack}

	\[ eval\ (Ite\ (Val\ 1)\ (Add\ (Val\ 2)\ (Val\ 3))\ (Add\ (Val\ 4)\ (Val\ 5))) = 5\]

As the \vm\ and interpreter are in agreement,
we have shown an example of the compiler 
satisfying the compiler correctness specification

\[ \Exec c\ (eval\ (Ite\ x\ y\ z):s) 
	= exec (\Compp  (Ite\ x\ y\ z) c)\ s  \]

\subsubsection{Interpretation}

%\subsubsection{proof}
%
%\begin{align*}
%	&\Exec c\ (eval\ (Ite\ x\ y\ z):s) \\
%	=\, & \{\mbox{defintion of}\ eval\} \\ 
%	&\Exec c\ (if\ eval\ x\ \not= 0\ then\ eval\ y\ else\ eval\ z :s) \\
%	=\, & \{define\: \Exec (ITE\ c) (k : m : n : s) = \Exec c\ ((if\ k \not=0\ then\ m : s\ else\ n) : s \} \\
%	& \Exec (ITE\ c)\ (eval\ x : eval\ y : eval\ z : s) \\
%	=\, & \{\mbox{induction hypothesis}\ for\ x \} \\
%	& \Exec (\Compp  x\ (ITE\ c))\ (eval\ y : eval\ z : s) \\
%	=\, & \{\mbox{induction hypothesis}\ for\ y \} \\
%	& \Exec (\Compp  y\ (\Compp  x\ (ITE\ c)))\ (eval\ z : s) \\
%	=\, & \{\mbox{induction hypothesis}\ for\ z\} \\
%	& \Exec (\Compp  z\ (\Compp  y\ (\Compp  x\ (ITE\ c))))\ s \\
%	=\, & \{\mbox{defintion of}\ comp' \} \\
%	& exec (\Compp  (Ite\ x\ y\ z) c)\ s \\
%	&QED
%\end{align*} 

In retrospect, this kind of evaluation of the condition
is eager; both cases regardless of the
condition's result, are executed
while only one branch of code needs to be.
This can avoided at if we can instead
evaluate the condition at compile time
and throw away the code for the case
that we don't need to execute.

\subsection{Lazy evaluation}

\newcommand{\lite}{$Lite$}

Our ``Lazy if then else'' function
 will be called \lite.

	\[ \textbf{data}\ Expr = ... | Lite\ Expr\ Expr\ Expr \]

and it's semantics are

\begin{equation}
eval(Lite\ x\ y\ z) \\
	= if\ eval\ x \not= 0 then\ eval\ y\ else\ eval\ z 
			\label{evallite}
\end{equation}

Expressions cannot be lazily evaluated
so \lite\ has the same semantics
as an \ite\ expression,
because lazy evaluation means evaluating
something only when the evaluation function
is called on it,
so being able to lazily evaluate something 
by calling the evaluator on it,
would be contradictory.

\subsubsection{Calculation}

Our inductive calculation of \lite,
begins in the same way
\begin{align*}
	&\Exec (\Compp  (Lite\ x\ y\ z)\ c)\ s \\
	=\, & \{specification\ (2) \} \\
	&\Exec c\ (eval\ (Lite\ x\ y\ z) : s) \\
	=\, & \{\mbox{defintion of}\ eval\} \\
	&\Exec c\ (if\ eval\ x\ \not= 0\ then\ eval\ y\ else\ eval\ z : s)
\end{align*}

Like with \ite\ our calculation halts here,
our aim with this time is that, again by using
the expression $x$ as our condition,
rather than deciding upon what value throw away
we instead decide upon two code branches, $ct$ and $ce$,
containing code of the complied $y$ and $z$ expressions.

	\[ LITE :: Code \rightarrow Code \rightarrow Code \]
	\[ \Exec (LITE\ ct\ ce)\ (eval\ x:s) 
	= \Exec c\ (if\ eval\ x\ \not= 0\ then\ eval\ y\ else\ eval\ z : s) \]

We cannot use this equation as a definition of exec 
because $c,\ y$ and $z$ are unbound in the 
body of the expression\cite[page 10]{bandh}.
However we can bind them in $ct$ and $ce$.
The compile function \comp\ requires that any code is followed by
more code (unless it is a HALT),
so not only do  $ct$ and $ce$ contain the code for expressions
 $y$ and $z$ but also the continuation code $c$

\begin{eqnarray*}
	ct &=& \Compp  y\ c \\
	ce &=& \Compp  z\ c
\end{eqnarray*}

In summary our generalised formal partial specification is
\begin{equation*}
	\Exec (LITE\ (\Compp  y\ c)\ (\Compp  z\ c) )\ (k:s) 
= \Exec (if\ k \not= 0\ then\ \Compp  y\ c\ else\ \Compp  z\ c)\ s 
\end{equation*}
which makes the rest of our calculation straightforward

\begin{align*}
	&\Exec c\ (if\ eval\ x\ \not= 0\ then\ eval\ y\ else\ eval\ z : s) \\
	=\, & \{\mbox{defintion of}\ exec\} \\
	&\Exec (LITE\ (\Compp  y\ c)\ (\Compp  z\ c) )\ (eval\ x : s) \\
	=\, & \{\mbox{induction hypothesis}\ for\ x\} \\
	&\Exec (\Compp  x\ ((LITE\ (\Compp  y\ c)\ (\Compp  z\ c)))\ s
\end{align*}

From which we may deduce 

	\[ \Compp  (Lite\ x\ y\ z)\ c 
		= \Compp  x\ (LITE\ (\Compp  y\ c)\ (\Compp  z\ c)) \]

This method poses a problem;
on the right hand side of this equation,
$c$ appears twice, meaning the code not only 
doubles in length, but doubles in \emph{compile time}.
This would cause a compile time-complexity of
\( T(n) = \mathcal{O}(2^n) \)
where $n$ is the number of \lite\ expressions.
Surely there must be a way to avoid this.

The problem comes from the double use of $c$,
at the moment this is necessary because \compp\
takes an \expr\ and \code\ as arguments and is in
each branch of code,
however they could instead \emph{share}
a code continuation if we used a different compile function
which would allow a single expression 
(and all sub-expressions contained within)  
to be compiled without continuation code of it's own,
unlike \compp, also LITE would need 3 code arguments in
it's constructor and we would need a way of 
reuniting the condition's code back with the rest of the code $c$
as~$``:\ cons''$ would not work.

\begin{eqnarray*}
f\ (Lite\ x\ y\ z)\ c &=& f'\ x\ (LITE\ (f\ y)\ (f\ z)\ c) \\
\Exec (LITE\ (f\ y)\ (f\ z)\ c) (k : s) 
&=& \Exec ((if \not=0\ then\ (f\ y)\ else\ (f\ z)) : c)\ s 
\end{eqnarray*}

But this is an optimisation problem out of the scope of this dissertation.

In summary, we have discovered the following 
definitions for the compiler and \vm.

\begin{eqnarray}
&\Compp  (Lite\ x\ y\ z)\ c \nonumber \\
	&= \Compp  x\ (LITE\ (\Compp  y\ c)\ (\Compp  z\ c)) \label{complite} \\
&\Exec (LITE\ ct\ ce)\ (eval\ x:s) \nonumber \\
	&= \Exec c\ (if\ eval\ x\ \not= 0\ then\ eval\ y\ else\ eval\ z : s) \label{execlite}
\end{eqnarray}

\subsubsection{Testing}

To test our definitions we can use the Haskell compiler
to compile and execute an example \lite expression,
which will be the same expression as we used
on it's the eager twin for comparison.

\[ \Exec (\Comp (Lite\ (Val\ 1)\
		 (Add\ (Val\ 2)\ (Val\ 3))\ 
		(Add\ (Val\ 4)\ (Val\ 5)))))\ [\, ] \]

\subsubsection{Compilation}

Compiling by hand:
\begin{align*}	
&\Comp (Lite\ (Val\ 1)\ (Add\ (Val\ 2)\ (Val\ 3))\ (Add\ (Val\ 4) (Val\ 5))) \\
=\, & \{ \mbox{defintion of}\ \Comp followed\ by\ equation\ \ref{complite}\ \} \\
&\Compp  (Val\ 1) (LITE\ (\Compp  (Add\ (Val\ 2)\ (Val\ 3))\ HALT)\ (\Compp   (Add\ (Val\ 4)\ (Val\ 5)))) \\
=\, & \{ equation\ \ref{compval}, \ref{compadd} \} \\
&\PUSH 1\ (LITE\ (\Compp  (Add\ (Val\ 2)\ (Val\ 3))\ HALT)\ (\Compp  (Add\ (Val\ 4)\ (Val\ 5)))) \\
=\, & \{ equation\ 8\ twice \} \\
&\PUSH 1\ (LITE\ (\Compp  (Val\ 2)\ (\Compp  (Val\ 3)\ (ADD\ HALT))\ (\Compp   (Val\ 4)\ (\Compp  (Val\ 5)\ (ADD\ HALT)))) \\
=\, & \{ equation\ 9\ four\ times \} \\
&\PUSH 1\ (LITE\ (\PUSH 2\ (\PUSH 3\ (ADD\ HALT))) (\PUSH 4\ (\PUSH 5 (ADD\ HALT))))
\end{align*}

Using the compile function \\Comp on this expression 
in the Haskell implementation yields the same result:

\begin{align*}	
&\Comp (Lite\ (Val\ 1)\
		 (Add\ (Val\ 2)\ (Val\ 3))\ 
		(Add\ (Val\ 4)\ (Val\ 5)))) \\
&= \PUSH 1\ (LITE\ 
		(\PUSH 2\ (\PUSH 3\ 
		(ADD\ HALT))) 
		(\PUSH 4\ (\PUSH 5 (ADD\ HALT))))
\end{align*}

\subsubsection{Execution}

%\begin{eqnarray}
%	\Exec  (LITE\ ct\ ce)\ (k:s) &=&  exec (if\ k\ \not= 0\ then\ ct\ else\ ce)\ s \\
%	\Exec (\PUSH n\ c) s         &=&  \Exec c\ (n:s) \\
%	\Exec  (ADD\ c)\ s     &=&  \Exec c\ ((n+m) : s) 
%\end{eqnarray}

\begin{align*}
&\Exec (\PUSH 1\ (LITE\ (\PUSH 2\ (\PUSH 3\ (ADD\ HALT))) (\PUSH 4\ (\PUSH 5 (ADD\ HALT)))))\ [\, ] \\
&=\{equation\ \ref{execpush} \} \\
&\Exec (LITE\ (\PUSH 2\ (\PUSH 3\ (ADD\ HALT))) (\PUSH 4\ (\PUSH 5 (ADD\ HALT))))\ [1] \\
&=\{equation\ \ref{execlite} \} \\
&\Exec (\PUSH 2\ (\PUSH 3\ (ADD\ HALT)))\ [\, ] \\
&=\{equation\ \ref{execpush}\ twice \} \\
&\Exec (ADD\ HALT)\ [3, 2] \\
&=\{equation\ \ref{execadd} \} \\
&\Exec HALT\ [5] \\
=\, & \{equation\ \ref{exechalt}\} \\
&[5]
\end{align*}

Using the Haskell implementation of the \vm.
\begin{align*}	
&\Exec (\PUSH 1\ (LITE\ 
	(\PUSH 2\ (\PUSH 3\ (ADD\ HALT))) 
	(\PUSH 4\ (\PUSH 5 (ADD\ HALT))))) \\
&= [5]
\end{align*}

\subsubsection{Interpretation}

\begin{align*}
&eval\ (Lite\ (Val\ 1) 
		(Add\ (Val\ 2) (Val\ 3)) 
		(Add\ (Val\ 4) (Val\ 5))) \\
=\, & \{ equation\ \ref{evallite} \}
&
\end{align*}

In the Haskell implementation of the
interpreter:

\[ eval\ (Lite\ (Val\ 1) (Add\ (Val\ 2) (Val\ 3)) (Add\ (Val\ 4) (Val\ 5)))  = 5\]


Which agrees with the execution of the 
compiled code of the expression.

\subsubsection{Proof}

Finally we come to proving our calculation.
We aim to show that our definitions for \lite
satisfy the specification

\[ \Exec c\ (eval\ (Lite\ x\ y\ z):s) = exec (\Compp  (Lite\ x\ y\ z) c)\ s  \]

\begin{align*}
&\Exec c\ (eval\ (Lite\ x\ y\ z):s) \\
=\, & \{ \mbox{defintion of}\ eval \} \\
&\Exec c\ ((if\ eval\ x\ \not= 0\ then\ eval\ y\ else\ eval\ z) :s) \\
=\, & \{ define\: \Exec (LITE\ (\Compp  x\ c) (\Compp  y\ c) (k : s) \\
&= \Exec (if\ k \not=0\ then\ (\Compp  y\ c)\ else\ (\Compp  z\ c))\ s \} \\
& \Exec (LITE\ (\Compp  y\ c)\ (\Compp  z\ c))\ (eval\ x : s) \\
=\, & \{ \mbox{defintion of}\ comp' \} \\
& \Exec (\Compp  x\ (LITE\ (\Compp  y\ c)\ (\Compp  z\ c)))\ s \\
=\, & \{\mbox{defintion of}\ comp' \} \\
&= exec (\Compp  (Lite\ x\ y\ z) c)\ s \\
QED
\end{align*}

\subsection{Summary}

In conclusion we have calculated the following definitions
												\cite[page 11]{bandh}:

\begin{eqnarray*}
	&\textbf{data}\ Code &= ...ITE\ Code | LITE\ Code\ Code \\
	&comp 				  &:: Expr \rightarrow Code \\
	&\Comp x			  &= \Compp  x\ HALT \\
	&comp'				  &:: Expr \rightarrow Code \rightarrow Code \\
	&\Compp  (Ite\ x\ y\ z) 
				&= \Compp  z\ (\Compp  y\ (\Compp  x\ (ITE c))) \\
	&\Compp  (Lite\ x\ y\ z) 
				&= \Compp  x\ (LITE\ (\Compp  y\ c)\ (\Compp  z\ c)) \\
	&\Exec (ITE\ c)\ (k:m:n:s) 
						&= \Exec c\ ((if\ k \not=0\ then\ m\ else\ n):s) \\
	&\Exec (LITE\ ct\ ce)\ (k:s) 
						&= \Exec (if\ k \not=0\ then\ ct\ else\ ce)\ s
\end{eqnarray*}

We have seen that via 
induction on the arguments of the 
\vm\ we can not only manipulate
stack elements but also code.
But our language is still very
basic.
Could we introduce more structures
to make the language more complicated;
with more features that resemble
an actual programming language?
\BH\ certainly do, by using 
multiple code continuations they
implement exception handling and the
``compilation techniques arising naturally''
through calculations\cite[page 24]{bandh}.

\section{Bindings, $L_b$} \label{langbind}

Variables are a key component
of a lot of programming languages;
they allow users to easily reference
an object without needing to recompute.
Computers use memory to store information
which programs and programmers a like may
take advantage of.
Variables may be declared by \emph{binding}
a pair of two pieces of information:
a name, and a value.
Our \eval\ function as of yet 
cannot do such an operation
because it does not manipulate any kind of
data structure of it's own,
it only iterates through
expressions and interprets them.
\eval\ would require atleast one more argument
containing a set of bindings which it can
manipulate.

\subsection{Semantics}

step 1: define an evaluation 
	function in a compositional manner.

Our bindings structure will be called
an environment, it is a stack
of name-value pairs ($i$, $j$) where
a string $i$ paired to an integer $j$.
\newcommand{\env}{$Env$}

	\[ \textbf{type} \, Env = [(String,\ Int)]\]

The evaluation function needs to be updated
to take an \env\ as an argument as well as
an expression.

\begin{eqnarray*}
	&eval              	   		&::\  Expr \rightarrow Env \rightarrow Int \\
	&eval\ (Val\ n)\ bs 		&=   n \\
	&eval\ (Add\ x\ y)\ bs		&=   eval\ x\ bs\ +\ eval\ y\ bs \\
	&eval\ (Ite\ x\ y\ z)\ bs	&=   if\ (eval\ x\ bs) \not= 0\ then\ (eval\ y\ bs)\ else\ (eval\ z\ bs) \\
	&eval\ (Lite\ x\ y\ z)\ bs 	&=   if\ (eval\ x\ bs) \not= 0\ then\ (eval\ y\ bs)\ else\ (eval\ z\ bs)
\end{eqnarray*}

All of our functions
have been calculated without need of environments,
therefore we can be reasonably sure that simply adding in the
\env argument won't affect them\footnote{
brackets have been added around the expressions for ease of reading}.

\newcommand{\lets}{$Let$}
\newcommand{\var}{$Var$}

Now the expression that will make a binding,
we'll call ``\lets''.
\lets\ has the concrete syntax:
\( Let\ v = x\ in\ y\),
again without a parser to do
lexical analysis, we need to use
abstract syntax, and our constructor
for it

	\[ \textbf{data}\ Expr = ... |\ Let\ String\ Expr\ Expr \]

\lets\ creates a new binding,
by pushing the String-Int pair
onto the \env, to reference a variable we will
use a ``Var'' constructor

\[ \textbf{data}\ Expr = ... |\ Var\ String \]

The String is taken directly from the source
String part of the \lets\ expression,
however the value it's paired to 
needs to be computed inductively.

Therefore our semantics of \lets\ and \var\

\begin{eqnarray*}
&eval\ (Let\ v\ x\ y)\ bs &= eval\ y\ ((v,\ eval\ x\ bs):bs) \\
&eval\ (Var\ v)\ bs		    &=   valueOf\ v\ bs  \\
&valueOf\ &:: String \rightarrow Env \rightarrow Int \\
&valueOf\ s\ [\, ]\ &= error\ ``Binding\ out\ of\ scope?" \\
&valueOf\ s\ ((v,\ n):bs) &= if\ s == v\ then\ n\ else\ valueOf\ s\ bs
\end{eqnarray*}

valueOf is an auxiliary function,
it takes a string as input, iterates through an
environment, and attempts to match
the string to the strings in each binding.
It returns the value of the \emph{first}\footnote{
Should a variable name be bound to twice in a 
source expression and in the same scope,
only the latter binding will
be in effect} binding
to have a matching string. 
\linebreak

Sub-expressions inherit environments from their parent expressions,
and therefore the variables within them have the same \emph{scope},
except in the case of \lets\ where each sub-expression $x$ and $y$
has a different scope. 
To illustrate this, the following equations
have the resulting environment included on the RHS.
Our evaluator actually empties the environment 
after it's computation, 
but it's helpful to think of it like this

\begin{align}
eval\ (Add\ (Var\ ``a'')\ (Val\ 2))\ &[(``a'',\, 2)] 
			&= 4,\ [``a'',\, 2] \nonumber \\
eval\ (Let\ ``a''\ (Val\ 2)\ (Add\ (Var\ a)\ (Val\ 2))  )\ &[\, ] 
		&= 4,\ [(``a'',\, 2)] \nonumber \\ 
eval\ (Let ``b'' \nonumber \\
		(Let\ ``a''\ (Val\ 2) \
			 (Add\ (Var\ a)\ (Val\ 2))  ) \nonumber \\
		(Add\ (Var\ b)\ (Val\ 2)))\ &[\, ] 
		&= 6,\ [(``b'',\, 4),\ (``a'',\, 2)] \label{egletlet1} \\ 
eval\ (Let ``a'' \nonumber \\
		(Let\ ``b''\ (Val\ 2) \
			 (Add\ (Var\ a)\ (Val\ 2))  ) \nonumber \\
		(Add\ (Var\ b)\ (Val\ 2)))\ &[\, ] 
		&= ``Binding\ b\ out\ of\ scope'' \label{egletlet2} \nonumber \\
\end{align}

In equation (\ref{egletlet1})
the second \add\ inherits
the scope of \lets\ sub-expression 
preceding it, 
because it evaluates
\emph{within scope} of it.
Conversely with equation (\ref{egletlet2})
the first sub-expression tries to reference
a variable that is \emph{out of scope},
and our interpreter throws an error.



\subsection{Compiler Correctness}

Step 2: Define equations that specify the
	correctness of the compiler.

Our compiler specifications have been:

	\[ \Exec  (\Comp  x)\  s = eval\  x:s \]
	\[ \Exec  (\Compp   x\  c)\ s = \Exec  c\  (eval \, x:s) \]

However, these no longer hold
because our eval function has changed
with the introduction of environments,
therefore we need to update these equations.
\linebreak
Our \env\ specifies parings of 
variable names to values,
the compiler cannot compute any 
values on its own
but it can produce code that will
produce the same effect once executed.
Breaking down what the interpreter
does can indicate what the 
compiler and \vm\ should do.

\[eval(Let\ v\ x\ y)\ bs 
		= eval\ y\ ((v,\ eval\ x\ bs):bs) \]

NB: bs, although a new type it is just a list
of pairs, we could re-write it in equations as
[(vars, vals)] where vars are the variable names
and vals, their values,
but it is simpler to keep it as bs.

To evaluate a \lets, the interpreter
must do three things:
\begin{enumerate}
	\item Evaluate x in the current environment
	\item Bind the variable v to that value
	\item Evaluate y in the modified environment
\end{enumerate}

Clearly the compiler and \vm\ must have some kind of
environment of their own to
reflect changes in the environment.
The compiler cannot compute the value
parts of each pair,
it can however, 
store when and what variables are called.

\begin{eqnarray*}
	&\textbf{type}\  Context\ &= [String] \\
	&comp &::\ Expr \rightarrow Code \\
	&\Comp e &=\ \Compp  e\ [\,]\ HALT\ (*)\\
	&comp' &::\ Expr \rightarrow Context \rightarrow Code
\end{eqnarray*}

*\\Comp stays much the same except it's cxt
	is initially empty.

Remember, our aim at the moment
is to relate the compiler to the
semantics via a virtual machine.
If we tried to do update our compiler 
specifications now; 
without the proper definitions
for the \vm, we'd have

\begin{eqnarray*}
&\Exec (\Comp x)\ s  
	&= \Exec (\Compp  x\ [\,]\ c)\ s  \\
&exec\ (\Compp  x\ cxt\ c)\ s  
	&= exec\ c\ (eval\ x\ (Zip\ cxt\ vs):bs):s)
\end{eqnarray*}

Which cannot be used
because bs is still unbound.
bs is just a set of name-value pairs,
now we have variable names
that don't have paired values,
this can be left to the \vm.

We can use\footnote{
There may be a way to have the variable values
on the run-time stack, but it's
simpler to use a new one}
a new stack to
manipulate these variable values.
\exec should take as input
the a pair of:
it's current run-time stack,
and the values stack,
and then output the modified versions of both,
that is

\begin{eqnarray*}
&\textbf{type}\ Memory\ &= (Stack,\ Stack) \\
&exec &::\ Code \rightarrow Memory \rightarrow Memory \\
&\Exec (\Compp  x\ cxt\ c) (s,\ vs) &= \Exec c\ ((eval\ x\ bs):s,\ vs)
\end{eqnarray*}

We now have a way of storing variable names
and their values, 
just in two different places.
To update the compiler correctness equations,
we need a function to pair up the names
to values.
That is the ``Zip'' function in Haskell

	\[ \Exec (\Comp e)\ (s,\ vs) 
		= \Exec (\Compp  e\ [\,]\ HALT)\ (s,\ vs) \]
	\[ \Exec (\Compp  e\ cxt\ c)\ (s,\ vs) 
		= \Exec c\ ((eval\ e\ (Zip\ cxt\ vs):s,\ vs) \]

Because our equations for \eval\
use the $bs$ symbol for environments,
it will be useful to formally state:

\begin{eqnarray}
&Zip\ (x:xs)\ (y:ys) &= (x,\, y):(Zip\ xs\ ys)  \\ \label{ziden}
&Zip\ cxt\ vs &= bs \label{zcxtvs}
\end{eqnarray}
	
These equations satisfy the full description
of step 2 in their \BH's General methodology
\cite[page 42]{bandh}.


\subsection{Calculation}

Step 3: Calculate definitions that satisfy
	the correctness of the compiler

Now that we have our compiler equations,
we can calculate definitions that satisfy
them by constructive rule induction
starting from the LHS of \thref{spec4}\cite[page 42]{bandh}.

\begin{align*}
	&\Exec (\Compp  (Let\ v\ x\ y)\ cxt\ c)\ (s,\ vs) \\
	=\, & \{ specification\ 4 \} \\
	&\Exec c\ (eval\ (Let\ v\ x\ y)\ (Zip\ cxt\ vs):s,\ vs) \\
	=\, & \{\mbox{defintion of}\ Zip,\ \mbox{defintion of}\ eval\} \\
	&\Exec c\ (eval\ y\ (\ (v,\ eval\ x\ bs) :bs) : s,\ vs)
\end{align*}

There are no more definitions to apply.

We aim to apply the inductive 
hypotheses for $x$ and $y$,
however our original ones will 
not do because they won't tell us
anything about changes of context.
We know, by the definition of our interpreter,
that $x$ needs to be evaluated first and 
bound to $v$ in the environment, so it can be 
referenced by any sub-expression
in $y$.
The Zip function connects the environment
to our context and values stacks.
To update an environment
we can use the definition of zip (\ref{ziden}),
where $x$ and $y$ are the new $v$ and $\chi$.

\[ Zip\ (v:xs)\ (\chi:ys) = (v,\, \chi):(Zip\ xs\ ys) = (v,\, \chi):bs \]

$y$ is evaluated with this environment.
Making the new inductive hypothesis for $x$ and $y$

\begin{eqnarray*}
	&\Exec (\Compp  x\ cxt\ c')\ (s,\ vs)
		&= \Exec c'\ (eval\ x\ bs : s,\ vs)\\
	&\Exec (\Compp  y\ (v:cxt)\ c'')\ (s,\ \chi : vs) 
		&= \Exec c''\ (eval\ y\ 
					(
					(v,\ \chi) : Zip\ cxt\ vs) : s,\ vs
					)\\
\end{eqnarray*}

NB:The code arguments are $c'$ and $c''$ 
here because we know we need a code instruction
to perform the binding, making it different to $c$,
and $c''$ is the code after the binding has been made.

To better fit the induction hypothesis for $y$,
apply the definition of Zip to the last step in the calculation
where \( \chi = eval\ x\ bs,\ bs = Zip\ cxt\ vs \)

\[ (v,\ eval\ x\ bs) :bs = (v,\, \chi):bs = (v,\, \chi):(Zip\ cxt\ vs) \]

To be able to use the induction hypothesis for $y$,
we need to have some value on $vs$ to take the place of $\chi$,
this value is unknown but is definitely an integer\footnote{
at the moment it's
type is the only thing that matters, not it's value,
but it will always be $\chi$\ because of the next step}.

\[ \Exec c''\ (s,\ \chi : vs) = \Exec c\ (s,\ vs) \]

Substituting the specific value $\chi$ for the general value $n$

\begin{eqnarray*}
&TEL\ &::\ Code \rightarrow Code \\
&\Exec (TEL\ c)\ (s,\ n:vs) &= \Exec c\ (s,\ vs)
\end{eqnarray*}

That is, $TEL$ removes the top the of the values stack.
A variable would have been bound to it as we will see,
but we will never be in a situation where we refer the wrong
value to a variable, because by construction a 

Using this to continue the calculation

\begin{align*}
&\Exec c\ (eval\ y\ (\ (v,\ eval\ x\ bs) :bs) : s,\ vs) \\
=\, & \{ \mbox{defintion of}\ Zip \} \\
&\Exec c\ (eval\ y\ (v,\, \chi):(Zip\ cxt\ vs) : s,\ vs) \\
=\, & \{ \mbox{defintion of}\ \Exec TEL\} \\
&\Exec (TEL\ c)\ (v,\, \chi):(Zip\ cxt\ vs) : s,\ \chi : vs) \\
=\, & \{ \mbox{induction hypothesis}\ for\ y \} \\
&\Exec (\Compp  y\ (v:cxt)\ (TEL\ c))\ (s,\ \chi : vs)
\end{align*}

Now to be able to use the induction hypothesis for $x$
we need a value to not be on $vs$ but rather on $s$.
We solve the equation 

\[ \Exec c'\ (\chi : s,\ vs) = \Exec c\ (s,\ \chi : vs) \]

Substituting the specific value $\chi$ for the general value $n$

\begin{eqnarray*}
 	&LET\ &::\ Code \rightarrow Code \\
 	&\Exec (LET\ c)\ (n:s,\ vs) &= \Exec c\ (s,\ n:vs)
\end{eqnarray*}

continuing the calculation

\begin{align*}
&\Exec (\Compp  y\ (v:cxt)\ (TEL\ c))\ (s,\ \chi : vs) \\
=\, & \{\mbox{defintion of}\ \Exec LET\} \\
&\Exec (LET\ (\Compp  y\ (v:cxt)\ (TEL\ c)))\ (\chi : s,\ vs)\\
=\, & \{ \chi = eval\ x\ bs \} \\
&\Exec (LET\ (\Compp  y\ (v:cxt)\ (TEL\ c)))\ ((eval\ x\ bs) : s,\ vs)\\
=\, & \{ \mbox{induction hypothesis}\ for\ x \} \\
&\Exec (\Compp  x\ cxt\ (LET\ (\Compp  y\ (v:cxt)\ (TEL\ c))))\ (s,\ vs)
\end{align*}

From this we conclude
\[ \Compp  (Let\ v\ x\ y)\ cxt\ c
		= \Compp  x\ cxt\ (LET\ (\Compp  y\ (v:cxt)\ (TEL\ c))) \]

\subsection{Testing}

\section{Function definition, $L_f$} \label{langfunc}

\section{Automated Testing} \label{autotesting}








\bibliographystyle{IEEEtran}
\bibliography{Finalproject}
\end{document}